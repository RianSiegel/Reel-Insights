{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba95031-404c-4dc6-b419-e9756b6a3e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import spacy\n",
    "import logging\n",
    "from charset_normalizer import from_path\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim.models import LdaModel\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1071d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# load spaCy model\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea33e35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to read screenplay\n",
    "def read_screenplay(file_path):\n",
    "    try:\n",
    "        result = from_path(file_path).best()\n",
    "        with open(file_path, 'r', encoding=result.encoding) as file:\n",
    "            lines = file.readlines()\n",
    "        logging.info(f\"Successfully read file {file_path}\")\n",
    "        return ''.join(lines[1:])\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error reading file {file_path}: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a968c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to separate scenes\n",
    "def separate_scenes(text):\n",
    "    try:\n",
    "        scenes = []\n",
    "        raw_scenes = [scene.strip() for scene in text.split('=' * 50) if scene.strip()]\n",
    "        for raw_scene in raw_scenes:\n",
    "            scene_lines = raw_scene.split('\\n')\n",
    "            scene_text = '\\n'.join(scene_lines[1:]).strip()\n",
    "            scenes.append(scene_text)\n",
    "        logging.info(f\"Separated text into {len(scenes)} scenes\")\n",
    "        return scenes\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error separating scenes: {str(e)}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c291af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to merge scenes with less than 100 words with following scene\n",
    "def merge_short_scenes(scenes, min_words=100):\n",
    "    merged_scenes = []\n",
    "    current_scene = \"\"\n",
    "    for scene in scenes:\n",
    "        current_scene_word_count = len(current_scene.split())\n",
    "        scene_word_count = len(scene.split())\n",
    "        if current_scene_word_count + scene_word_count < min_words:\n",
    "            current_scene += \" \" + scene\n",
    "        else:\n",
    "            if current_scene:\n",
    "                merged_scenes.append(current_scene.strip())\n",
    "            current_scene = scene\n",
    "    if current_scene:\n",
    "        merged_scenes.append(current_scene.strip())\n",
    "    logging.info(f\"Merged scenes into {len(merged_scenes)} longer scenes\")\n",
    "    \n",
    "    return merged_scenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3451dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to identify character names with regex (character names before dialogue lines are in uppercase in most screenplays)\n",
    "def identify_character_names(text):\n",
    "    character_name_pattern = re.compile(r'\\n\\s*([A-Z][A-Z\\s]+)\\s*\\n')\n",
    "    potential_characters = character_name_pattern.findall(text)\n",
    "    cleaned_characters = [re.sub(r'\\s+$', '', char) for char in potential_characters]\n",
    "    \n",
    "    return cleaned_characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe6b9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to remove character names, preprocess text\n",
    "def preprocess_text(text):\n",
    "    character_names = identify_character_names(text)\n",
    "    for name in character_names:\n",
    "        text = text.replace(name, '')\n",
    "    text = text.lower()\n",
    "    # replace multiple consecutive whitespace characters with a space\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    # replace all non-word characters with a space\n",
    "    text = re.sub(r'\\W', ' ', text)\n",
    "    # process cleaned text using spaCy\n",
    "    doc = nlp(text)\n",
    "    # extract tokens from processed text, but only include alphabetic tokens\n",
    "    tokens = [token.text for token in doc if token.is_alpha]\n",
    "    \n",
    "    # join tokens back into single string\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdf7953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to remove stopwords\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in STOPWORDS] for doc in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2806272a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to train LDA model\n",
    "def train_lda_model(texts, num_topics=10, passes=10):\n",
    "    # create dictionary from texts\n",
    "    dictionary = Dictionary(texts)\n",
    "    # filter out words that appear in fewer than 5 documents or more than 50% of documents\n",
    "    dictionary.filter_extremes(no_below=5, no_above=0.5)\n",
    "    # convert texts into bag-of-words format (list of (word_id, word_count) for each document)\n",
    "    corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "    # train lda model on corpus with specified number of topics and passes\n",
    "    lda_model = LdaModel(corpus=corpus, num_topics=num_topics, id2word=dictionary, passes=passes)\n",
    "    \n",
    "    return lda_model, dictionary, corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcffde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get dominant topic\n",
    "def get_dominant_topic(lda_model, text, dictionary):\n",
    "    # convert text into bag-of-words\n",
    "    bow = dictionary.doc2bow(text)\n",
    "    # get topic distribution for text from lda model\n",
    "    topic_distribution = lda_model.get_document_topics(bow)\n",
    "    # find dominant topic and return its index\n",
    "    dominant_topic = max(topic_distribution, key=lambda x: x[1])[0]\n",
    "    \n",
    "    return dominant_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a314a7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to find dominant topic in each document\n",
    "def assign_dominant_topics(texts, lda_model, dictionary):\n",
    "    dominant_topics = [get_dominant_topic(lda_model, text, dictionary) for text in texts]\n",
    "    \n",
    "    return dominant_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db255baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to compute topic coherence scores\n",
    "def compute_topic_coherence(dominant_topics, lda_model):\n",
    "    topic_vectors = lda_model.get_topics()\n",
    "    # normalize vectors\n",
    "    topic_vectors = topic_vectors / np.linalg.norm(topic_vectors, axis=1, keepdims=True)\n",
    "    # get vectors for dominant topics\n",
    "    scene_vectors = [topic_vectors[topic] for topic in dominant_topics]\n",
    "    # compute pairwise cosine similarities\n",
    "    similarities = cosine_similarity(scene_vectors)\n",
    "    # compute average similarity (excluding self-similarity)\n",
    "    num_scenes = len(scene_vectors)\n",
    "    # subtract diagonal (self-similarity)\n",
    "    sum_similarities = np.sum(similarities) - num_scenes\n",
    "    avg_similarity = sum_similarities / (num_scenes * (num_scenes - 1))\n",
    "    \n",
    "    return avg_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b64415",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_screenplay(filename, screenplay_folder):\n",
    "    try:\n",
    "        file_path = os.path.join(screenplay_folder, filename)\n",
    "        pattern = re.compile(r'_0*(\\d+)\\.txt$')\n",
    "        match = pattern.search(filename)\n",
    "        if not match:\n",
    "            logging.warning(f\"Could not extract imdbid from filename: {filename}\")\n",
    "            return None, None\n",
    "\n",
    "        imdbid = match.group(1)\n",
    "        text = read_screenplay(file_path)\n",
    "        if text is None:\n",
    "            return None, None\n",
    "\n",
    "        scenes = separate_scenes(text)\n",
    "        merged_scenes = merge_short_scenes(scenes, min_words=100)\n",
    "        preprocessed_scenes = [preprocess_text(scene) for scene in merged_scenes]\n",
    "        preprocessed_scenes = remove_stopwords(preprocessed_scenes)\n",
    "        lda_model, dictionary, corpus = train_lda_model(preprocessed_scenes, num_topics=10, passes=10)\n",
    "        dominant_topics = assign_dominant_topics(preprocessed_scenes, lda_model, dictionary)\n",
    "        overall_coherence = compute_topic_coherence(dominant_topics, lda_model)\n",
    "        \n",
    "        logging.info(f\"Processed {filename}: imdbid={imdbid}, coherence={overall_coherence}\")\n",
    "        return int(imdbid), overall_coherence\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error processing {filename}: {str(e)}\")\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0877ee99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_screenplay(filename, screenplay_folder):\n",
    "    try:\n",
    "        # construct full file path for screenplay\n",
    "        file_path = os.path.join(screenplay_folder, filename)        \n",
    "        # define regex pattern to extract imdbid from filename\n",
    "        pattern = re.compile(r'_0*(\\d+)\\.txt$')        \n",
    "        # apply regex pattern to filename to find imdbid\n",
    "        match = pattern.search(filename)\n",
    "        if not match:\n",
    "            # log warning if imdbid can't be extracted and return None\n",
    "            logging.warning(f\"Could not extract imdbid from filename: {filename}\")\n",
    "            return None, None\n",
    "\n",
    "        # extract imdbid from filename\n",
    "        imdbid = match.group(1)\n",
    "        \n",
    "        # read screenplay content from file\n",
    "        text = read_screenplay(file_path)\n",
    "        if text is None:\n",
    "            return None, None\n",
    "\n",
    "        # split screenplay into scenes\n",
    "        scenes = separate_scenes(text)        \n",
    "        # merge scenes shorter than 100 words\n",
    "        merged_scenes = merge_short_scenes(scenes, min_words=100)        \n",
    "        # preprocess each scene (e.g., lowercasing, removing non-alpha characters)\n",
    "        preprocessed_scenes = [preprocess_text(scene) for scene in merged_scenes]        \n",
    "        # remove stopwords from preprocessed scenes\n",
    "        preprocessed_scenes = remove_stopwords(preprocessed_scenes)        \n",
    "        # train lda model on preprocessed scenes\n",
    "        lda_model, dictionary, corpus = train_lda_model(preprocessed_scenes, num_topics=10, passes=10)        \n",
    "        # assign dominant topic to each scene\n",
    "        dominant_topics = assign_dominant_topics(preprocessed_scenes, lda_model, dictionary)        \n",
    "        # calculate topic coherence score based on dominant topics\n",
    "        overall_coherence = compute_topic_coherence(dominant_topics, lda_model)        \n",
    "        # log imdbid and coherence score\n",
    "        logging.info(f\"Processed {filename}: imdbid={imdbid}, coherence={overall_coherence}\")\n",
    "        \n",
    "        # return imdbid and overall coherence score\n",
    "        return int(imdbid), overall_coherence\n",
    "\n",
    "    except Exception as e:\n",
    "        # log error message if an exception occurs during processing\n",
    "        logging.error(f\"Error processing {filename}: {str(e)}\")\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3400730-d314-48e1-a88a-b1351474c82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        # load metadata df\n",
    "        df = pd.read_csv('data/movie_metadata_final.csv')\n",
    "\n",
    "        # folder containing screenplay files\n",
    "        screenplay_folder = 'data/screenplay_data/data/scene_separated_texts'\n",
    "\n",
    "        # list to store results\n",
    "        results = []\n",
    "\n",
    "        # iterate over screenplay files sequentially\n",
    "        for filename in os.listdir(screenplay_folder):\n",
    "            if filename.endswith('.txt'):\n",
    "                result = process_screenplay(filename, screenplay_folder)\n",
    "                if result[0] is not None and result[1] is not None:\n",
    "                    results.append(result)\n",
    "\n",
    "        # create new df to store imdbid and overall_coherence\n",
    "        coherence_df = pd.DataFrame(results, columns=['imdbid', 'overall_coherence'])\n",
    "\n",
    "        # drop rows where imdbid or overall_coherence is None\n",
    "        coherence_df.dropna(inplace=True)\n",
    "\n",
    "        # save results in df\n",
    "        coherence_df.to_csv('data/movie_coherence_scores.csv', index=False)\n",
    "\n",
    "        # merge coherence scores back into original metadata df\n",
    "        df = df.merge(coherence_df, on='imdbid', how='left')\n",
    "\n",
    "        # save updated df\n",
    "        df.to_csv('data/movie_metadata_with_coherence.csv', index=False)\n",
    "        \n",
    "        logging.info(\"Finished processing all screenplays and saved results.\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in main execution: {str(e)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
